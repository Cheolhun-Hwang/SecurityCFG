import os
import csv
import math
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Tuple, Set, Iterable, Optional
import pandas as pd

# =========================
# ê³µí†µ ìœ í‹¸
# =========================
def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)

def safe_name(name: str) -> str:
    return str(name).replace("/", "_").replace("\\", "_")

def save_class_csv(items: List[Tuple[str, int]], out_path: Path):
    ensure_dir(out_path.parent)
    rows = [(str(g), int(c)) for g, c in items]
    rows.sort(key=lambda t: (-t[1], t[0]))
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["x_ngram", "count"])
        w.writerows(rows)

def save_debug_csv(items: Iterable, out_path: Path, header: Iterable[str]):
    ensure_dir(out_path.parent)
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(list(header))
        for row in items:
            if isinstance(row, (list, tuple)):
                w.writerow(list(row))
            else:
                w.writerow([row])

# =========================
# 1) ë¼ë²¨ ë¡œë“œ: id -> class
# =========================
def load_labels(csv_path: str) -> Dict[str, str]:
    df = pd.read_csv(csv_path)
    cols = {c.lower(): c for c in df.columns}
    if 'id' not in cols or 'class' not in cols:
        raise ValueError("trainLabels.csvì—ëŠ” 'Id'ì™€ 'Class' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤. (ëŒ€ì†Œë¬¸ì ë¬´ê´€)")
    id_col = cols['id']; cls_col = cols['class']
    df[id_col] = df[id_col].astype(str)
    return dict(zip(df[id_col], df[cls_col].astype(str)))

# =========================
# 2) cfg/<id>.txt ì½ê¸°
#  - íŒŒì¼ ë‚´ ì¤‘ë³µ ì œê±°(set)ë¡œ 'ë“±ì¥ ì—¬ë¶€'ë§Œ ì¹´ìš´íŠ¸
# =========================
def read_ngrams_file(txt_path: Path) -> Set[str]:
    grams = set()
    with open(txt_path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            g = line.strip()
            if g:
                grams.add(g)
    return grams

# =========================
# 3) í´ë˜ìŠ¤ë³„ ì§‘ê³„
#    (x-3ê·¸ë¨ì´ â€˜ë“±ì¥í•œ íŒŒì¼ ìˆ˜â€™ë¥¼ ì¹´ìš´íŠ¸)
# =========================
def aggregate_by_class(cfg_dir: str, id_to_class: Dict[str, str]):
    cfg_path = Path(cfg_dir)
    if not cfg_path.is_dir():
        raise FileNotFoundError(f"cfg ë””ë ‰í† ë¦¬ ì—†ìŒ: {cfg_dir}")

    class_counters = defaultdict(Counter)   # class -> Counter(gram -> ë“±ì¥ 'íŒŒì¼ ìˆ˜')
    class_file_counts = defaultdict(int)    # class -> íŒŒì¼ ìˆ˜
    class_nonempty_counts = defaultdict(int)# class -> ë¹„ì–´ìˆì§€ ì•Šì€ íŒŒì¼ ìˆ˜
    class_file_ids = defaultdict(list)      # class -> [id, id, ...]
    ids_without_label = []                  # cfgì— ìˆëŠ”ë° ë¼ë²¨ì— ì—†ëŠ” id

    for txt in cfg_path.glob("*.txt"):
        file_id = txt.stem
        cls = id_to_class.get(file_id)
        if cls is None:
            ids_without_label.append(file_id)
            continue

        grams = read_ngrams_file(txt)
        class_file_counts[cls] += 1
        class_file_ids[cls].append(file_id)

        if grams:
            class_nonempty_counts[cls] += 1
            class_counters[cls].update(grams)

    return (class_counters, class_file_counts, class_nonempty_counts,
            class_file_ids, ids_without_label)

# =========================
# 4) 50% ì´ìƒ ì¶œí˜„ í•„í„°
# =========================
def filter_by_threshold(class_counters, class_file_counts, threshold_ratio: float = 0.5):
    filtered = {}
    thresholds = {}
    for cls, counter in class_counters.items():
        total = class_file_counts.get(cls, 0)
        thr = math.ceil(total * threshold_ratio) if total > 0 else 0
        thresholds[cls] = thr

        kept = []
        dropped = []
        for g, c in counter.items():
            if thr > 0 and c >= thr:
                kept.append((g, c))
            else:
                dropped.append((g, c))
        filtered[cls] = {'kept': kept, 'dropped_below_thr': dropped}
    return filtered, thresholds

# =========================
# 5-A) í´ë˜ìŠ¤ ê°„ ì¤‘ë³µ ì œê±° (ì™„ì „ ê³ ìœ ë§Œ ìœ ì§€)
# =========================
def drop_shared_ngrams(filtered_counts_by_class):
    gram_to_classes = defaultdict(set)
    for cls, parts in filtered_counts_by_class.items():
        for g, _ in parts['kept']:
            gram_to_classes[g].add(cls)

    unique_per_class = {}
    dropped_shared = {}
    for cls, parts in filtered_counts_by_class.items():
        kept = []
        dropped = []
        for g, c in parts['kept']:
            if len(gram_to_classes[g]) == 1:
                kept.append((g, c))
            else:
                dropped.append((g, c))
        unique_per_class[cls] = kept
        dropped_shared[cls] = dropped
    return unique_per_class, dropped_shared

# =========================
# 5-B) ì§€ì›ìœ¨ ë¹„ìœ¨ë¡œ ì¬ë°°ì • (ê³µìœ  n-gramì„ ë‹¨ì¼ í´ë˜ìŠ¤ë¡œ ë°°ì •)
#   - í›„ë³´: ì„ê³„ í†µê³¼(kept)ì— ì˜¤ë¥¸ í´ë˜ìŠ¤ë“¤
#   - best_sup / second_sup >= min_ratio AND (best_sup - second_sup) >= min_delta ì¼ ë•Œë§Œ ë°°ì •
#   - ë‹¨ì¼ í›„ë³´ë©´ ë°”ë¡œ ë°°ì •
# =========================
def allocate_shared_by_ratio(class_counters, class_file_counts, filtered_counts_by_class,
                             min_ratio: float = 1.25, min_delta: float = 0.05):
    # ê° í´ë˜ìŠ¤ì˜ kept ëª©ë¡ set
    kept_by_class = {cls: {g for g, _ in parts['kept']}
                     for cls, parts in filtered_counts_by_class.items()}
    # í›„ë³´ gram ì§‘í•©
    all_kept = set().union(*kept_by_class.values()) if kept_by_class else set()

    assigned = {cls: [] for cls in filtered_counts_by_class.keys()}       # class -> list[(g, cnt)]
    ambiguous_global = []  # [(g, best_cls, best_sup, second_cls, second_sup)]
    winner_of_gram = {}    # g -> winner class or None

    for g in sorted(all_kept):
        # í›„ë³´ í´ë˜ìŠ¤: í•´ë‹¹ gramì´ keptì— í¬í•¨ëœ í´ë˜ìŠ¤
        candidates = [cls for cls, s in kept_by_class.items() if g in s]
        if not candidates:
            continue

        # ì§€ì›ìœ¨ ê³„ì‚°: sup = (ë“±ì¥ íŒŒì¼ ìˆ˜ / total_files)
        supports = []
        for cls in candidates:
            total = class_file_counts.get(cls, 0)
            cnt = class_counters[cls].get(g, 0)
            sup = (cnt / total) if total > 0 else 0.0
            supports.append((cls, sup, cnt))
        supports.sort(key=lambda t: (-t[1], t[0]))

        best_cls, best_sup, best_cnt = supports[0][0], supports[0][1], supports[0][2]
        second_sup = supports[1][1] if len(supports) >= 2 else 0.0
        second_cls = supports[1][0] if len(supports) >= 2 else None

        # ë‹¨ì¼ í›„ë³´ â†’ ë°”ë¡œ ë°°ì •
        if len(candidates) == 1:
            assigned[best_cls].append((g, best_cnt))
            winner_of_gram[g] = best_cls
            continue

        # ë¹„ìœ¨/ì°¨ì´ ê¸°ì¤€ìœ¼ë¡œ ë°°ì •
        if (second_sup == 0 and best_sup > 0) or \
           (second_sup > 0 and best_sup / second_sup >= min_ratio and (best_sup - second_sup) >= min_delta):
            assigned[best_cls].append((g, best_cnt))
            winner_of_gram[g] = best_cls
        else:
            ambiguous_global.append((g, best_cls, best_sup, second_cls, second_sup))
            winner_of_gram[g] = None

    # ë””ë²„ê·¸ìš©: ê° í´ë˜ìŠ¤ ê´€ì ì—ì„œ â€œë‚¨ì˜ ìŠ¹ë¦¬ë¡œ ìƒì€ í•­ëª©â€/â€œì• ë§¤í•´ì„œ ë³´ë¥˜ëœ í•­ëª©â€
    lost_to_other = {cls: [] for cls in filtered_counts_by_class.keys()}
    ambiguous_per_class = {cls: [] for cls in filtered_counts_by_class.keys()}

    for g in all_kept:
        winner = winner_of_gram.get(g)
        for cls in kept_by_class.keys():
            if g not in kept_by_class[cls]:
                continue
            cnt = class_counters[cls].get(g, 0)
            if winner is None:
                # ì• ë§¤í•´ì„œ ë°°ì • ë³´ë¥˜
                ambiguous_per_class[cls].append((g, cnt))
            elif winner != cls:
                # ë‹¤ë¥¸ í´ë˜ìŠ¤ì— ë°°ì •ë¨
                lost_to_other[cls].append((g, cnt))

    return assigned, lost_to_other, ambiguous_per_class, ambiguous_global

# =========================
# 6) í´ë˜ìŠ¤ë³„ ì§€ì›ìœ¨ í…Œì´ë¸” (ì§„ë‹¨)
# =========================
def analyze_shared_for_class(class_counters, class_file_counts, filtered_by_thr,
                             target_cls: str, out_csv: Path):
    """target_clsì˜ ì„ê³„ í†µê³¼ n-gramì— ëŒ€í•´ ëª¨ë“  í´ë˜ìŠ¤ ì§€ì›ìœ¨(support)ì„ í‘œë¡œ ì €ì¥"""
    ensure_dir(out_csv.parent)
    target_kept = {g for g, _ in filtered_by_thr.get(target_cls, {}).get('kept', [])}
    classes = sorted(class_counters.keys())

    rows = []
    header = ["x_ngram"] + [f"{cls}_support" for cls in classes]
    for g in sorted(target_kept):
        row = [g]
        for cls in classes:
            total = class_file_counts.get(cls, 0)
            cnt = class_counters[cls].get(g, 0)
            sup = (cnt / total) if total > 0 else 0.0
            row.append(f"{sup:.6f}")
        rows.append(row)
    save_debug_csv(rows, out_csv, header=header)

# =========================
# 7) ìš”ì•½ ì €ì¥
# =========================
def save_debug_summary(cls: str,
                       out_dir: Path,
                       class_file_counts: Dict[str, int],
                       class_nonempty_counts: Dict[str, int],
                       thresholds: Dict[str, int],
                       kept_after_thr: List[Tuple[str,int]],
                       dropped_below_thr: List[Tuple[str,int]],
                       final_items: List[Tuple[str,int]],
                       dropped_shared_or_lost: List[Tuple[str,int]],
                       ambiguous_for_cls: Optional[List[Tuple[str,int]]] = None,
                       class_file_ids: Optional[Dict[str, List[str]]] = None,
                       reason_override: Optional[str] = None):
    ensure_dir(out_dir)
    p = out_dir / f"{safe_name(cls)}__summary.txt"

    total_files = class_file_counts.get(cls, 0)
    nonempty = class_nonempty_counts.get(cls, 0)
    thr = thresholds.get(cls, 0)

    # ìë™ reason
    reason = []
    if reason_override:
        reason.append(reason_override)
    else:
        if total_files == 0:
            reason.append("NO_FILES_FOR_CLASS")
        elif nonempty == 0:
            reason.append("ALL_FILES_EMPTY")
        elif len(kept_after_thr) == 0:
            reason.append("ALL_DROPPED_AT_THRESHOLD")
        elif len(final_items) == 0:
            reason.append("NO_ITEMS_AFTER_SHARED_HANDLING")
        else:
            reason.append("HAS_FEATURES")

    with open(p, "w", encoding="utf-8") as f:
        f.write(f"class: {cls}\n")
        f.write(f"files_total: {total_files}\n")
        f.write(f"files_nonempty: {nonempty}\n")
        f.write(f"threshold(ceil(files*ratio)): {thr}\n")
        f.write(f"kept_after_threshold: {len(kept_after_thr)}\n")
        f.write(f"dropped_below_threshold: {len(dropped_below_thr)}\n")
        f.write(f"final_items: {len(final_items)}\n")
        f.write(f"dropped_shared_or_lost: {len(dropped_shared_or_lost)}\n")
        if ambiguous_for_cls is not None:
            f.write(f"ambiguous_shared_for_cls: {len(ambiguous_for_cls)}\n")
        if class_file_ids:
            f.write(f"file_ids: {', '.join(class_file_ids.get(cls, []))}\n")
        f.write(f"reason: {', '.join(reason)}\n")

# =========================
# 8) ë©”ì¸ íŒŒì´í”„ë¼ì¸ (+ ì§„ë‹¨/ì „ëµ ì„ íƒ)
# =========================
def build_class_cfg_with_diagnostics(
    labels_csv: str,
    cfg_dir: str = "result/cft",              # x-3ê·¸ë¨ íŒŒì¼ë“¤
    out_dir: str = "result/cfg_class",        # ìµœì¢… í´ë˜ìŠ¤ë³„ CSV
    debug_dir: str = "result/cfg_debug",      # ë””ë²„ê·¸ ì‚°ì¶œë¬¼
    threshold_ratio: float = 0.5,
    shared_strategy: str = "drop",            # "drop" | "allocate_ratio" | "keep_all"
    min_ratio: float = 1.25,                  # allocate_ratioìš©
    min_delta: float = 0.05,                  # allocate_ratioìš©
    supports_for_classes: Optional[List[str]] = None  # ì˜ˆ: ["7"] or ["3","6","7"] or None
):
    """
    shared_strategy:
      - "drop"           : ê³µìœ  n-gramì€ ì™„ì „íˆ ì œê±°(ê³ ìœ ë§Œ ìœ ì§€)
      - "allocate_ratio" : ì§€ì›ìœ¨ ë¹„ìœ¨/ì°¨ì´ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì¼ í´ë˜ìŠ¤ë¡œ ë°°ì •
      - "keep_all"       : ê³µìœ ë„ ìœ ì§€(ì„ê³„ í†µê³¼ë§Œ í•˜ë©´ ëª¨ë‘ ìœ ì§€)
    """
    out_base = Path(out_dir)
    dbg_base = Path(debug_dir)
    ensure_dir(out_base); ensure_dir(dbg_base)

    # 1) ë¼ë²¨ ë¡œë“œ
    id_to_class = load_labels(labels_csv)

    # 2) ì§‘ê³„
    (class_counters,
     class_file_counts,
     class_nonempty_counts,
     class_file_ids,
     ids_without_label) = aggregate_by_class(cfg_dir, id_to_class)

    if ids_without_label:
        save_debug_csv(sorted(ids_without_label),
                       dbg_base / "__ids_without_label.txt",
                       header=["ids_without_label"])

    # 3) ì„ê³„ í•„í„°
    filtered_by_thr, thresholds = filter_by_threshold(class_counters, class_file_counts, threshold_ratio)

    # 4) ê³µìœ  ì²˜ë¦¬ ì „ëµ
    if shared_strategy == "drop":
        final_per_class, dropped_shared = drop_shared_ngrams(filtered_by_thr)
        # ë””ë²„ê·¸ ì €ì¥
        for cls, parts in filtered_by_thr.items():
            safe_cls = safe_name(cls)
            save_debug_csv(list(class_counters.get(cls, Counter()).items()),
                           dbg_base / f"{safe_cls}__raw_counts.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(parts['kept'],
                           dbg_base / f"{safe_cls}__kept_threshold.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(parts['dropped_below_thr'],
                           dbg_base / f"{safe_cls}__dropped_below_threshold.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(dropped_shared.get(cls, []),
                           dbg_base / f"{safe_cls}__dropped_shared.csv",
                           header=["x_ngram","file_count"])

            # ìš”ì•½
            save_debug_summary(
                cls=cls,
                out_dir=dbg_base,
                class_file_counts=class_file_counts,
                class_nonempty_counts=class_nonempty_counts,
                thresholds=thresholds,
                kept_after_thr=parts['kept'],
                dropped_below_thr=parts['dropped_below_thr'],
                final_items=final_per_class.get(cls, []),
                dropped_shared_or_lost=dropped_shared.get(cls, []),
                ambiguous_for_cls=None,
                class_file_ids=class_file_ids,
                reason_override=None
            )

    elif shared_strategy == "allocate_ratio":
        assigned, lost_to_other, ambiguous_per_class, ambiguous_global = allocate_shared_by_ratio(class_counters, class_file_counts, filtered_by_thr,
                                     min_ratio=min_ratio, min_delta=min_delta)

        final_per_class = assigned
        # ë””ë²„ê·¸ ì €ì¥
        save_debug_csv(ambiguous_global,
                       dbg_base / "__ambiguous_global.csv",
                       header=["x_ngram","best_cls","best_sup","second_cls","second_sup"])

        for cls, parts in filtered_by_thr.items():
            safe_cls = safe_name(cls)
            save_debug_csv(list(class_counters.get(cls, Counter()).items()),
                           dbg_base / f"{safe_cls}__raw_counts.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(parts['kept'],
                           dbg_base / f"{safe_cls}__kept_threshold.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(parts['dropped_below_thr'],
                           dbg_base / f"{safe_cls}__dropped_below_threshold.csv",
                           header=["x_ngram","file_count"])

            save_debug_csv(final_per_class.get(cls, []),
                           dbg_base / f"{safe_cls}__allocated.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(lost_to_other.get(cls, []),
                           dbg_base / f"{safe_cls}__lost_to_other.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(ambiguous_per_class.get(cls, []),
                           dbg_base / f"{safe_cls}__ambiguous_shared.csv",
                           header=["x_ngram","file_count"])

            # reason íŒë‹¨
            reason_override = None
            if len(parts['kept']) > 0 and len(final_per_class.get(cls, [])) == 0:
                # keptëŠ” ìˆì—ˆìœ¼ë‚˜ ìµœì¢… ë°°ì • 0ì¸ ê²½ìš°
                if len(ambiguous_per_class.get(cls, [])) > 0 and len(lost_to_other.get(cls, [])) == 0:
                    reason_override = "ALL_AMBIGUOUS_SHARED"
                elif len(lost_to_other.get(cls, [])) > 0:
                    reason_override = "ALL_ALLOCATED_TO_OTHERS"

            save_debug_summary(
                cls=cls,
                out_dir=dbg_base,
                class_file_counts=class_file_counts,
                class_nonempty_counts=class_nonempty_counts,
                thresholds=thresholds,
                kept_after_thr=parts['kept'],
                dropped_below_thr=parts['dropped_below_thr'],
                final_items=final_per_class.get(cls, []),
                dropped_shared_or_lost=lost_to_other.get(cls, []),
                ambiguous_for_cls=ambiguous_per_class.get(cls, []),
                class_file_ids=class_file_ids,
                reason_override=reason_override
            )

    elif shared_strategy == "keep_all":
        # ì„ê³„ í†µê³¼í•œ ê²ƒ ì „ë¶€ ìœ ì§€ (ê³µìœ ë„ í—ˆìš©)
        final_per_class = {cls: parts['kept'] for cls, parts in filtered_by_thr.items()}
        for cls, parts in filtered_by_thr.items():
            safe_cls = safe_name(cls)
            save_debug_csv(list(class_counters.get(cls, Counter()).items()),
                           dbg_base / f"{safe_cls}__raw_counts.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(parts['kept'],
                           dbg_base / f"{safe_cls}__kept_threshold.csv",
                           header=["x_ngram","file_count"])
            save_debug_csv(parts['dropped_below_thr'],
                           dbg_base / f"{safe_cls}__dropped_below_threshold.csv",
                           header=["x_ngram","file_count"])
            save_debug_summary(
                cls=cls,
                out_dir=dbg_base,
                class_file_counts=class_file_counts,
                class_nonempty_counts=class_nonempty_counts,
                thresholds=thresholds,
                kept_after_thr=parts['kept'],
                dropped_below_thr=parts['dropped_below_thr'],
                final_items=final_per_class.get(cls, []),
                dropped_shared_or_lost=[],
                ambiguous_for_cls=None,
                class_file_ids=class_file_ids,
                reason_override=None
            )
    else:
        raise ValueError("shared_strategyëŠ” 'drop' | 'allocate_ratio' | 'keep_all' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    # 5) ìµœì¢… CSV ì €ì¥
    for cls, items in final_per_class.items():
        save_class_csv(items, out_base / f"{safe_name(cls)}.csv")

    # 6) (ì„ íƒ) íŠ¹ì • í´ë˜ìŠ¤ ì§€ì›ìœ¨ í…Œì´ë¸” ì €ì¥
    if supports_for_classes:
        for c in supports_for_classes:
            analyze_shared_for_class(
                class_counters, class_file_counts, filtered_by_thr,
                target_cls=c,
                out_csv=dbg_base / f"{safe_name(c)}__shared_supports.csv"
            )

    print(f"âœ… ìµœì¢… CSV â†’ {out_base}")
    print(f"ğŸ§ª ë””ë²„ê·¸ ì‚°ì¶œë¬¼ â†’ {dbg_base}")

# =========================
# ì‚¬ìš© ì˜ˆì‹œ
# =========================
if __name__ == "__main__":
    # ì˜ˆ) Kelihos_ver1(í´ë˜ìŠ¤ '7')ì˜ ë¹ˆ ì´ìœ ë¥¼ ì¤„ì´ê³  ì‹¶ë‹¤ë©´,
    #    ê³µìœ  ì œê±° ëŒ€ì‹  'allocate_ratio'ë¡œ ì¬ë°°ì • + ì§€ì›ìœ¨ í…Œì´ë¸”ë„ ìƒì„±
    build_class_cfg_with_diagnostics(
        labels_csv=r"D:\malware-classification\trainLabels.csv",
        cfg_dir="result/train/cfg",
        out_dir="result/train/cfg_class",
        debug_dir="result/train/cfg_debug",
        threshold_ratio=0.25,
        shared_strategy="allocate_ratio",   # <- í•µì‹¬
        min_ratio=1.25,                     # 1.25~1.5 ê¶Œì¥
        min_delta=0.05,
        supports_for_classes=["3", "6", "7"]          # 7ë²ˆ í´ë˜ìŠ¤ ì§€ì›ìœ¨ í‘œ ë¤í”„
    )
    pass
